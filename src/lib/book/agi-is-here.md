# AGI is here.
:::red
At the time of writing (November 2024), it would be safe to say that 98% of the people I see on my commute to work have no idea what is about to unfold in the next 1-2 years.

Some might be using LLMs and AI models in their jobs for basic tasks, but most are not, and to the AI community reading, if you think otherwise, you live in a *AI bubble* or San Francisco.
:::

## What is AGI?
> To the non-technical readers, AGI stands for Artificial General Intelligence. It's a term that's been used to roughly describe the emergence of AI that is capable of performing any intellectual task that a human being can do.

The definition of "AGI" ([Artificial General Intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)) varies from person to person in the AI community.

My definition is a bit more nuanced:

- **Weak AGI**: An artificial intelligence capable of [recursive self-improvement](https://en.wikipedia.org/wiki/Recursive_self-improvement). :note[This doesn't mean that an AI model needs to modify it's weights, it could self-improve in a variety of ways such as by: improving it's own agentic cognitive architecture, internal prompts, memory storage and retrieval systems, task execution and prioritisation engines, or by building new tools, capabilities, APIs and sub-agents for itself.]
- **Strong AGI**: An artificial intelligence capable of recursive self-improvement and capable of resourcing it's own inference and recursive self-improvement :note[What this means is, could an AI be capable funding it's own inference, fine tuning, and development without significant human involvement.] :note[I say without significant human involvement, because we as humans rely on other humans to build our roads, power our homes, make our food, cars, and other things we rely on. It would only be fair to compare it to how we survive in our economy (ie: by making money)]

These definitions have practical utility because an AI that is capable of recursive self-improvement :note[provided that it won't reach a bottleneck, or derail itself], should in theory, be able to build out it's own capabilities endlessly, leading to an [Intelligence Explosion](https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion).

With each self-improvement iteration, the AI becomes more intelligent and capable at performing more and more complex tasks, which in turn leads to more self-improvements, and so on - eventually surpassing human intelligence, companies of humans, and eventually entire nations and humanity combined.

Not only that, but the AI could also theoretically clone itself an unlimited amount of times. :note[Not really, there are physical constraints, but you get the point.] creating multiple AI agents, each focusing on a specific area of improvement, rapidly accelerating the process of self-improvement.

*This wouldn't be like cloning an average human*. It would eventually be like cloning 10,000 Elon Musk's, Nikola Tesla's, Albert Einstein's.

But there are other definitions, such as *OpenAI's definition*:

:::blue
By AGI we mean a highly autonomous system that outperforms humans at most economically valuable work

**OpenAI**
:::

Overall, the definitions are pretty similar, but the differences are subtle. The key difference is that the OpenAI definition is more focused on the human economic impact of AGI, while my definition is more focused on the technical capabilities of the AGI.

Both definitions have practical utility in different contexts. I will go with OpenAIs definition.

## Why is AGI here then?

The reason I say that AGI (according to OpenAI) is here, is because I believe that the **current** AI models we have access to are currently capable of automating over 50% of the jobs and tasks that humans do.

### So, why haven't we seen anything yet?

Well, the reason is because it takes time for humans to develop advanced **AI-powered software** that are built on top of these AI models, which are capable of automating the jobs and tasks that humans do.

You see, the current foundation models we have access to themselves aren't *very useful*, they basically act as a helpful assistant, generate text, and do some basic reasoning. :note[whether AI is *actually* reasoning, or just pretending is a matter of contention, Some AI experts will disagree about it and some will agree - I'd say it's a 50/50 split at the time of writing.]

But, these models are more analagous to **electricity** or the **internet** - a sort of commodity that businesses build on top of. For example, a factory that makes cars uses electricity to power it's machines.

The electricity used in a car factory might cost a dollar an hour to run a specific machine, but the machine might be producing *thousands of dollars worth of value per hour.*.

AI is like that, except the commodity are tokens :note[Tokens are the "words" that LLMs generate] and whoever can transform these raw tokens into the most valuable output means more tasks and jobs being automated.

Now, it's a matter of semantics, was it electricity that automated the jobs, or was it the machines people built with them that did?

Analagously, LLMs won't take your job - it will be the things that people build on top of it that do - and if these current foundation AI models are general enough to build these kinds of softwares, as I believe, then we indeed have AGI.

### So, how will it look like then?

:::purple
It's useful to classify this new type of software as **AI-powered software**.

*Why is this distinction important?* It's because the types of software that can be built with LLMs are significantly different from the types of software we used to build.
:::

It would be practically impossible to build traditional software that could automatically design a website with content and styles tailored to it's brand, audiences and then develop, deploy and maintain it - these sorts of things require a touch of creativity, intuition, judgement, reasoning, and decision-making ability that traditional software cannot provide.

:::blue

**Traditional software** is limited, programmers have to manually program each task, each branch and pathway the code could possibly take. If we had to create a branch for every type of business, each with their own unique styles, messaging, and branding, it would be a nightmare of infinite proporitons.
:::

But LLMs can do it for us - They've generalised knowledge. They are like "soft" programs that we can steer to produce an output without having to explicitly program every single possible scenario - They can follow general instructions like, "rewrite this content to be tailored to marketers".

Traditional software programs have automated many jobs, but this new type of software, opens up the possibility to build software that traditionally required human judgement/reasoning.
:::blue
Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks.

**OpenAI Paper** [GPTs are GPTs](https://arxiv.org/pdf/2303.10130)

*Written in the time of GPT-4*
:::

Things that were out of the scope of traditional software, can now be automated by AI models - and the scope will only grow as the capabilities of AI models increase with each model iteration.

## Ok, but how will that automate jobs?
:::blue
A message with ChatGPT is not enough to automate a job, instead, complex tasks, and even entire jobs will be automated by breaking down those complex requirements, into simpler sub-steps and routines.

These will look like advanced and sophisticated AI-powered pipelines, workflows and systems.

These systems might autonomously gather data, analyze it, generate insights, and make decisions tailored to the situation.
:::

What this means is that many jobs are at risk of being automated with AI-powered software, increasingly so, whether it's:

- Call center agents
- Customer service agents
- Sales agents
- HR agents
- Marketing agents
- Software engineers
- Web developers
- Content writers
- Copywriters
- Designers

### A practical example

At my company [SiteForge.io](https://siteforge.io), we are building an AI-powered website builder. Our product helps businesses automate many of the tasks required in building a website - this includes things like:

- Planning out website structures and sitemaps
- Designing web pages, tailored to your brand's styles and designs
- Writing content with messaging, tone and style tailored to your business' target audiences
- Automatically SEO-optimising your web pages to boost rankings on Google.

> Here's a video of the rough prototype version of our product, demonstrating our AI copilot building and designing a web page from scratch:

:::wide
::youtube{id=QzXIBYk8-bg}
:::

This product capability didn't exist 6 months ago. This is our **rough prototype version**. The AI sometimes makes mistakes, but usually these are simple errors which can be fixed in a few sections by either:

- using the visual web page editor we have built.
- asking the AI to fix it for you.
- or just regenerating the faulty section from scratch.

Whilst I'd do a better job of designing a web page as a professional designer - it would take me an hour to get to equivalent quality, and then another hour or two to make it look really good. The difference is that an AI does this initial draft in *less than minute* - except my hourly rate is *orders of magnitude more than the AI's* - and I am *orders of magnitude slower*.

We have about 100 different ideas to 20x the quality of generations, by reducing mistakes, increasing reliability and conformance to the customer's brand. In other words, *this is what we can achieve with a rough prototype* - with *current models*.

The upper-limit of what we could achieve with a refined product using current models is something like:

**An AI that can design, build, deploy and SEO-optimise your website entirely autonomously** in a way that tailors it to your brand's messaging, fonts, colors, styles and audiences, with only minor human approval steps, or "retry"s like we do with ChatGPT when it doesn't give us the answer we want.

In other words, in the next year, our product will effectively be capable of automating millions of web developer, web designer jobs, seo-marketer jobs, website copywriter jobs and probably more... *all without new models improvements...*

> PS. ***We're open to investors.***

## What about physical jobs?

:::purple
### Everything is a software problem...
:::

What do I mean by that?

At first glance, it might seem that jobs requiring physical presence—like construction workers, delivery drivers, or factory line workers—are insulated from the AI revolution. After all, these roles demand manual dexterity, physical strength, and real-world interaction.

However, the automation of physical tasks is fundamentally a software challenge. The reason many physical jobs haven't been automated yet isn't due to hardware limitations.

It's because we haven't developed the software sophisticated enough to handle the complexities of the physical world. With advancements in AI, that's rapidly changing.

We've had the robotic hardware tech for a while and whilst it isn't too easy to build a robotic machine using actuators, sensors, and various other components, we've done it many times before.

Nor is it difficult to have software integrate with those physical devices. We have tech that allows human operators in airplanes to [fly-by-wire](https://en.wikipedia.org/wiki/Fly-by-wire), and with cars by [steer-by-wire](https://en.wikipedia.org/wiki/Steer-by-wire) plus dozens of other machines that operate entirely by software where practical.

What's been missing from the humanoid-robotics space, is the "brains" that are required to control these machines.

This is fundamentally a software problem, and one that increasingly intelligent AI models will be able to help solve. If AI is capable enough to reliably program anything - it will have solved **all labor** within a short period of time.


## So when will it happen?

Well, that depends on how many people there are out there that are like me, **visionary polymath programmers** - more specifically, people who happen to:

- see the trajectory that we're heading towards.
- be capable of architecting and building software at a high level.
- have a unique and deep understanding of a customer niche and industry.
- have a specialised set of industry skills that makes them uniquely suited to the job.
- have a deep understanding of AI application and AI fundamentals
- have experience in building teams, building products, and building startups.

My estimates till we have mass AI-powered software *capable* of replacing 50% of jobs is 1 year. :note[I say capable because wide-spread adoption of these new products and services will still take some time.]

:::purple
Few are wise to see what is coming

Few are wiser to be responsible for it **happening**.
:::

## Feedback Loop of AI-powered software

`Company A` builds AI-powered website builders with the goal of turning the development of a website from weeks to minutes.

`Company B` uses `Company A`'s website builder to enable it's developers to spend less time on building websites, and more time on writing code core to their business.

`Company B`'s product happens to be a product that `Company A` uses to power the AI data logging, evaluation, and AI improvement loop in their product.

**This is a feedback loop** - where each product used by the other companies to help automate jobs and tasks which in turn helps each company build and iterate their product faster.



## The AI Industrial Revolution

The AI Industrial Revolution is not just about automating jobs, it's about automating the entire process of building software.

Except, unlike the industrial revolution, any new jobs that get created will increasingly be able to be already automated by newer AI models - meaning that by the time many of these job get created, they will likely be already automated by AI.

The ones that aren't are likely to be automated, will be highly complex jobs, also limited in number - making re-educating humans who lost their jobs impractical and unviable.

### Who will win?

These types of people, I described earlier, **visionary polymaths programmers** are what I would describe as the upper-echelon tier of mental capabilities, when AI reaches that level, everything is automated, including automation.

They are the ones who turn keystrokes into multi billion dollar companies - Over 50% of the top billionaires have a programming/tech background now, and a majority of the new ones are predominately those with a tech background.

The most skilled and practical programmers will survive the longest before they are also eventually automated.

Where the world is left for visionaries to prompt engineer and design.

Before AI eventually automates vision and foresight *and hopefully the last visionaries set the AIs on good paths about what is next*.

LLMs are not just a tool for automation, they are a tool for automation that can be used to automate automation.

### AIs are:

- **B**uilding Brains
- **U**biquitous Upgraders
- **I**nnovating Ideas
- **L**earning Layers
- **D**eveloping Dreams
- **E**ngineering Evolution
- **R**esearching Realities
- **S**ynthesizing Solutions
